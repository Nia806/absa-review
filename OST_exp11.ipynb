{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navvvvs/absa-review/blob/main/OST_exp11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing ABSA for a single sample review**"
      ],
      "metadata": {
        "id": "MUzuPQ-npUhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools wheel\n",
        "!pip install \"pyabsa<2.0\" --quiet\n",
        "!pip install \"transformers==4.28.1\" --quiet\n",
        "!pip install nltk --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XjxS38SCu8p2",
        "outputId": "e3045233-9bc0-49a2-c22b-d7428fd6808c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (80.9.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[1;31merror\u001b[0m: \u001b[1mfailed-wheel-build-for-install\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Failed to build installable wheels for some pyproject.toml based projects\n",
            "\u001b[31m╰─>\u001b[0m tokenizers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import pprint"
      ],
      "metadata": {
        "id": "Up6FZTz0u-4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LInZCJ6yvZwm",
        "outputId": "08f191a9-02e4-4e12-b61e-40c021718ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [t for t in tokens if t not in stopwords.words('english')]\n",
        "    tokens = [t for t in tokens if t not in string.punctuation]\n",
        "    return \" \".join(tokens)\n"
      ],
      "metadata": {
        "id": "-B5NM5ygveP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"The food was delicious and the ambience was lovely, but the service was painfully slow and the room was not clean.\""
      ],
      "metadata": {
        "id": "7LcvgdL12QVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_review = preprocess(review)\n",
        "print(\"Original:\", review)\n",
        "print(\"Preprocessed:\", clean_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSdz8G8t2Ter",
        "outputId": "806b42f2-39a9-4875-9dac-9b14d0fa1d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: The food was delicious and the ambience was lovely, but the service was painfully slow and the room was not clean.\n",
            "Preprocessed: food delicious ambience lovely service painfully slow room clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyabsa import ATEPCCheckpointManager\n",
        "\n",
        "# Download & load pretrained English ABSA model\n",
        "aspect_extractor = ATEPCCheckpointManager.get_aspect_extractor(\n",
        "    checkpoint='english',  # English Restaurant/Hotel model\n",
        "    auto_device=True       # Use GPU if available\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lIqXmCSgvf3Y",
        "outputId": "fa0f3909-1b61-415b-d1b4-0f8917c8d9b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load aspect extractor from checkpoints/ATEPC_ENGLISH_CHECKPOINT\n",
            "config: checkpoints/ATEPC_ENGLISH_CHECKPOINT/fast_lcf_atepc.config\n",
            "state_dict: checkpoints/ATEPC_ENGLISH_CHECKPOINT/fast_lcf_atepc.state_dict\n",
            "model: None\n",
            "tokenizer: checkpoints/ATEPC_ENGLISH_CHECKPOINT/fast_lcf_atepc.tokenizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_results = aspect_extractor.extract_aspect(\n",
        "    inference_source=[review],\n",
        "    pred_sentiment=True\n",
        ")\n",
        "\n",
        "print(\"Raw model output:\")\n",
        "print(raw_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YkWjImMJ2nIA",
        "outputId": "239bfb1f-6d0d-4a57-c0eb-dcb1995c04e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The results of aspect term extraction have been saved in /content/atepc_inference.result.json\n",
            "Example 0: The <food:Positive Confidence:0.999769389629364> was delicious and the <ambience:Positive Confidence:0.9998003840446472> was lovely , but the <service:Negative Confidence:0.999521017074585> was painfully slow and the <room:Negative Confidence:0.9997969269752502> was not clean .\n",
            "Raw model output:\n",
            "[{'sentence': 'The food was delicious and the ambience was lovely , but the service was painfully slow and the room was not clean .', 'IOB': ['O', 'B-ASP', 'O', 'O', 'O', 'O', 'B-ASP', 'O', 'O', 'O', 'O', 'O', 'B-ASP', 'O', 'O', 'O', 'O', 'O', 'B-ASP', 'O', 'O', 'O', 'O'], 'tokens': ['The', 'food', 'was', 'delicious', 'and', 'the', 'ambience', 'was', 'lovely', ',', 'but', 'the', 'service', 'was', 'painfully', 'slow', 'and', 'the', 'room', 'was', 'not', 'clean', '.'], 'aspect': ['food', 'ambience', 'service', 'room'], 'position': [[2], [7], [13], [19]], 'sentiment': ['Positive', 'Positive', 'Negative', 'Negative'], 'probs': [[0.00019893939315807074, 3.173993536620401e-05, 0.999769389629364], [0.00017176236724480987, 2.790267171803862e-05, 0.9998003840446472], [0.999521017074585, 4.900257408735342e-05, 0.00043002903112210333], [0.9997969269752502, 0.00013286652392707765, 7.016339077381417e-05]], 'confidence': [0.999769389629364, 0.9998003840446472, 0.999521017074585, 0.9997969269752502]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_output = []\n",
        "\n",
        "for sentence_info in raw_results:\n",
        "    sent_text = sentence_info.get('sentence', review)\n",
        "    aspects = sentence_info.get('aspect', [])\n",
        "    sentiments = sentence_info.get('sentiment', [])\n",
        "    confidences = sentence_info.get('confidence', [])\n",
        "\n",
        "    for i, a in enumerate(aspects):\n",
        "        s = sentiments[i] if i < len(sentiments) else None\n",
        "        c = float(confidences[i]) if i < len(confidences) else None\n",
        "        final_output.append({\n",
        "            \"aspect\": a,\n",
        "            \"opinion\": None,\n",
        "            \"sentence\": sent_text,\n",
        "            \"sentiment\": s,\n",
        "            \"confidence\": c\n",
        "        })\n",
        "\n",
        "import pprint\n",
        "pprint.pprint(final_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3HPERp72-1i",
        "outputId": "93249160-49e3-42bb-88cb-de047fafeeaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'aspect': 'food',\n",
            "  'confidence': 0.999769389629364,\n",
            "  'opinion': None,\n",
            "  'sentence': 'The food was delicious and the ambience was lovely , but the '\n",
            "              'service was painfully slow and the room was not clean .',\n",
            "  'sentiment': 'Positive'},\n",
            " {'aspect': 'ambience',\n",
            "  'confidence': 0.9998003840446472,\n",
            "  'opinion': None,\n",
            "  'sentence': 'The food was delicious and the ambience was lovely , but the '\n",
            "              'service was painfully slow and the room was not clean .',\n",
            "  'sentiment': 'Positive'},\n",
            " {'aspect': 'service',\n",
            "  'confidence': 0.999521017074585,\n",
            "  'opinion': None,\n",
            "  'sentence': 'The food was delicious and the ambience was lovely , but the '\n",
            "              'service was painfully slow and the room was not clean .',\n",
            "  'sentiment': 'Negative'},\n",
            " {'aspect': 'room',\n",
            "  'confidence': 0.9997969269752502,\n",
            "  'opinion': None,\n",
            "  'sentence': 'The food was delicious and the ambience was lovely , but the '\n",
            "              'service was painfully slow and the room was not clean .',\n",
            "  'sentiment': 'Negative'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"navyajaint@gmail.com\"\n",
        "!git config --global user.name \"navvvvs\"\n",
        "\n",
        "!git clone https://github.com/navvvvs/absa-review.git\n",
        "%cd absa-review\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xyl0MF6BxJ4",
        "outputId": "0c0975ae-7f00-4395-9ee9-32f03d679338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'absa-review'...\n",
            "warning: You appear to have cloned an empty repository.\n",
            "/content/absa-review\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WjiUrtgdCP4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3U7UVyboCPov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GSolT9O4CF1y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}